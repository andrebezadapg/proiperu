{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting proi.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile proi.py\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "def plot_curves(data_dict:dict) -> None:\n",
    "    '''\n",
    "    Plot a response curve per media vehicle\n",
    "    \n",
    "    Args:\n",
    "        data_dict: collection of curve's data\n",
    "\n",
    "    Returns:\n",
    "        A plot with all media response curves\n",
    "    '''\n",
    "    positions = range(1, len(data_dict.keys()) + 1)\n",
    "    sizes = int(np.ceil(len(data_dict.keys())/2))\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    fig.suptitle('Nielsen Response Curves')\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    for i, k in enumerate(data_dict.keys()):\n",
    "        ax = fig.add_subplot(sizes, sizes, positions[i])\n",
    "        ax.plot(data_dict[k]['data']['Weekly Support'], data_dict[k]['data']['Prediction'])\n",
    "        ax.title.set_text(k)\n",
    "    plt.show()\n",
    "    \n",
    "def hill(x:float, a:float, b:float, c:float) -> float:\n",
    "    '''\n",
    "    Hill function\n",
    "    \n",
    "    Args:\n",
    "        x: input value\n",
    "        a, b,c: parameters to tune\n",
    "\n",
    "    Returns:\n",
    "        Use to estimated value for x, given parameters a, b and c\n",
    "    '''\n",
    "    return  a * np.power(x, b) / (np.power(c, b) + np.power(x, b))\n",
    "\n",
    "def poly2(x:float, a:float, b:float, c:float) -> float:\n",
    "    '''\n",
    "    Polynomial of degree 2 function\n",
    "        \n",
    "    Args:\n",
    "        x: input value\n",
    "        a, b,c: parameters to tune\n",
    "\n",
    "    Returns:\n",
    "        Use to estimated value for x, given parameters a, b and c\n",
    "    '''\n",
    "    return a * x + b * x**2 + c\n",
    "\n",
    "def poly3(x:float, a:float, b:float, c:float) -> float:\n",
    "    '''\n",
    "    Polynomial of degree 3 function\n",
    "        \n",
    "    Args:\n",
    "        x: input value\n",
    "        a, b,c: parameters to tune\n",
    "\n",
    "    Returns:\n",
    "        Use to estimated value for x, given parameters a, b and c\n",
    "    '''\n",
    "    return a * x + b * x**2 + c * x**3\n",
    "\n",
    "def log_(x:float, a:float, b:float, c:float) -> float:\n",
    "    '''\n",
    "    Log function\n",
    "        \n",
    "    Args:\n",
    "        x: input value\n",
    "        a, b,c: parameters to tune\n",
    "\n",
    "    Returns:\n",
    "        The estimated value for x, given parameters a, b and c\n",
    "    '''\n",
    "    return a * np.log(b + x) + c\n",
    "\n",
    "def cdf_(x:float, mu:float, sigma:float, c:float) -> float:\n",
    "    '''\n",
    "    CDF function\n",
    "        \n",
    "    Args:\n",
    "        x: input value\n",
    "        mu, sigma, c: parameters to tune\n",
    "\n",
    "    Returns:\n",
    "        The estimated value for x, given parameters a, b and c\n",
    "    '''\n",
    "    return scipy.stats.norm(mu,sigma).cdf(x) + c\n",
    "\n",
    "def weibull(u:float, shape:float, scale:float) -> float:\n",
    "    '''\n",
    "    Weibull distribution\n",
    "    \n",
    "    Args:\n",
    "        u: speed\n",
    "        shape: shape parameter k\n",
    "        scale: parameter A\n",
    "        \n",
    "    Returns:\n",
    "        The estimated value for u, shape, and scale\n",
    "    '''\n",
    "    return sum(log(stats.weibull_min.pdf(x, shape, 0., u)))\n",
    "\n",
    "def find_best_func(funcs:list, x:pd.Series, y:pd.Series, poly1d=True) -> tuple:\n",
    "    '''\n",
    "    Find the best function (r-squared-wise) to fit the original data per vehicle\n",
    "    \n",
    "    Args:\n",
    "        funcs: list of functions to use use\n",
    "        x: normalized impressions/trps\n",
    "        y: response\n",
    "\n",
    "    Returns:\n",
    "        The best fitted function and its parameters\n",
    "    '''\n",
    "    best_func = None\n",
    "    best_params = None\n",
    "    max_fit = -np.inf\n",
    "\n",
    "    for func in funcs:\n",
    "        try:\n",
    "            initialParameters = np.array([np.random.random(), np.random.random(), np.random.random()])\n",
    "            fittedParameters, pcov = curve_fit(func, x, y, initialParameters, method='lm')\n",
    "            modelPredictions = func(x, *fittedParameters) \n",
    "            absError = modelPredictions - y\n",
    "            Rsquared = 1.0 - (np.var(absError) / np.var(y))\n",
    "            \n",
    "            if Rsquared > max_fit:\n",
    "                best_func = func\n",
    "                best_params = fittedParameters\n",
    "                max_fit = Rsquared\n",
    "        except:\n",
    "            continue\n",
    "    if poly1d:\n",
    "        func = np.poly1d(np.polyfit(x, y, 5))\n",
    "        fittedParameters = []\n",
    "        modelPredictions = func(x)\n",
    "        absError = modelPredictions - y\n",
    "        Rsquared = 1.0 - (np.var(absError) / np.var(y))\n",
    "\n",
    "        if Rsquared > max_fit:\n",
    "            best_func = func\n",
    "            best_params = fittedParameters\n",
    "            max_fit = Rsquared\n",
    "            \n",
    "    print('r2:', round(max_fit,3))\n",
    "    \n",
    "    return best_func, best_params\n",
    "\n",
    "def norm_data(data_dict:dict) -> dict:\n",
    "    '''\n",
    "    Min-max normalize x-axis of vehicle's data\n",
    "    \n",
    "    Args:\n",
    "        data_dict: collection of curve's data\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with data normalized\n",
    "    '''\n",
    "    for k in data_dict.keys():\n",
    "        scaler = MinMaxScaler()\n",
    "        df = data_dict[k]['data'].copy()\n",
    "        df['Weekly Support'] = scaler.fit_transform(df[['Weekly Support']])\n",
    "        data_dict[k]['data_norm'] = df\n",
    "        data_dict[k]['scaler'] = scaler\n",
    "    return data_dict\n",
    "\n",
    "def fit_curves(funcs:list, data_dict:dict, poly1d:bool=True) -> dict:\n",
    "    '''\n",
    "    Fit all response curves and update dict\n",
    "    \n",
    "    Args:\n",
    "        funcs: list of functions to use use\n",
    "        data_dict: collection of curve's data\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with fitted curves\n",
    "    '''\n",
    "    data_dict = norm_data(data_dict)\n",
    "\n",
    "    for k in data_dict.keys():\n",
    "        print(k)\n",
    "        print('-'*10)\n",
    "        tmp = data_dict[k]['data_norm'].copy()\n",
    "        x = tmp['Weekly Support']\n",
    "        y = tmp['Prediction']\n",
    "\n",
    "        best_func, best_params = find_best_func(funcs, x, y, poly1d=poly1d)\n",
    "\n",
    "        tmp['pred'] = tmp['Weekly Support'].apply(lambda x: best_func(x, *best_params))\n",
    "        data_dict[k]['fitted'] = [best_func, best_params]\n",
    "        print()\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "def plot_fitted_curves(data_dict:dict) -> None:\n",
    "    '''\n",
    "    Plot a response curve per media vehicle and its fitted function\n",
    "    \n",
    "    Args:\n",
    "        data_dict: collection of curve's data\n",
    "\n",
    "    Returns:\n",
    "        A plot with all media response curves and its corresponding fitted function\n",
    "    \n",
    "    '''\n",
    "    positions = range(1, len(data_dict.keys()) + 1)\n",
    "    sizes = np.ceil(len(data_dict.keys())/2)\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    fig.suptitle('Nielsen Response Curves')\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    for i, k in enumerate(data_dict.keys()):\n",
    "        ax = fig.add_subplot(sizes, sizes, positions[i])\n",
    "        ax.plot(data_dict[k]['data_norm']['Weekly Support'], data_dict[k]['data_norm']['Prediction'], 'r')\n",
    "        ax.plot(data_dict[k]['data_norm']['Weekly Support'], data_dict[k]['data_norm']['Weekly Support'].apply(lambda x: data_dict[k]['fitted'][0](x, *data_dict[k]['fitted'][1])), 'b', linestyle='dashed')\n",
    "        ax.title.set_text(k)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_actual_curves(data_dict:dict, x:np.ndarray) -> None:\n",
    "    '''\n",
    "    Plot a response curve per media vehicle with it's actual value\n",
    "    \n",
    "    Args:\n",
    "        data_dict: collection of curve's data\n",
    "        x: array with solution values\n",
    "\n",
    "    Returns:\n",
    "        A plot with all media response curves and their corresponding solutions\n",
    "    \n",
    "    '''\n",
    "    positions = range(1, len(data_dict.keys()) + 1)\n",
    "    sizes = np.ceil(len(data_dict.keys())/2)\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    fig.suptitle('Nielsen Response Curves')\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    for i, k in enumerate(data_dict.keys()):\n",
    "        point = data_dict[k]['fitted'][0](x[i], *data_dict[k]['fitted'][1]) \n",
    "        ax = fig.add_subplot(sizes, sizes, positions[i])\n",
    "        ax.plot(data_dict[k]['data_norm']['Weekly Support'], data_dict[k]['data_norm']['Prediction'])\n",
    "        ax.plot(x[i], point, 'ro') \n",
    "        ax.title.set_text(k)\n",
    "    plt.show()\n",
    "\n",
    "def plot_solution_curves(data_dict:dict, x:np.ndarray, actual:np.ndarray) -> None:\n",
    "    '''\n",
    "    Plot a response curve per media vehicle with it's solution value\n",
    "    \n",
    "    Args:\n",
    "        data_dict: collection of curve's data\n",
    "        x: array with solution values\n",
    "        actual: array with actual values\n",
    "\n",
    "    Returns:\n",
    "        A plot with all media response curves and their corresponding solutions\n",
    "    \n",
    "    '''\n",
    "    positions = range(1, len(data_dict.keys()) + 1)\n",
    "    sizes = int(np.ceil(len(data_dict.keys())/2))\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    fig.suptitle('Nielsen Response Curves')\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    for i, k in enumerate(data_dict.keys()):\n",
    "        point = data_dict[k]['fitted'][0](x[i], *data_dict[k]['fitted'][1])\n",
    "        point_actual = data_dict[k]['fitted'][0](actual[i], *data_dict[k]['fitted'][1]) \n",
    "        ax = fig.add_subplot(sizes, sizes, positions[i])\n",
    "        ax.plot(data_dict[k]['data_norm']['Weekly Support'], data_dict[k]['data_norm']['Prediction'])\n",
    "        ax.plot(x[i], point, 'go')\n",
    "        ax.plot(actual[i], point_actual, 'ro') \n",
    "        ax.title.set_text(k)\n",
    "    plt.show()\n",
    "\n",
    "### Optimization\n",
    "def get_spend(s:float, data_dict:dict, vehicle:str) -> float:\n",
    "    '''\n",
    "    Compute spend given impressions: imp * cpp / ix * w\n",
    "    \n",
    "    Args:\n",
    "        s: normed impressions\n",
    "        data_dict: collection of curve's data\n",
    "        vehicle: media vehicle to compute for\n",
    "\n",
    "    Returns:\n",
    "        Spend for those impressions on that vehicle\n",
    "    '''\n",
    "    return data_dict[vehicle]['scaler'].inverse_transform([[s]])[0][0]  * data_dict[vehicle]['cpp'] / data_dict[vehicle]['ix_spend'] * data_dict[vehicle]['weeks'] \n",
    "\n",
    "def get_nos(y:float, data_dict:dict, vehicle:str) -> float:\n",
    "    '''\n",
    "    Compute NOS given impressions: imp / ix * w * su\n",
    "    \n",
    "    Args:\n",
    "        y: normed impressions\n",
    "        data_dict: collection of curve's data\n",
    "        vehicle: media vehicle to compute for\n",
    "        \n",
    "    Returns:\n",
    "        NOS for those impressions on that vehicle\n",
    "    '''\n",
    "    return data_dict[vehicle]['scaler'].inverse_transform([[y]])[0][0] / data_dict[vehicle]['ix_nos'] * data_dict[vehicle]['weeks'] * data_dict[vehicle]['fitted'][0](y, *data_dict[vehicle]['fitted'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
